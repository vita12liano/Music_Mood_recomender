{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b1f255",
   "metadata": {},
   "source": [
    "# Cell 1 - Import & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b580b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1da923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (169909, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>...</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>macro_cluster</th>\n",
       "      <th>subcluster</th>\n",
       "      <th>subcluster_label</th>\n",
       "      <th>is_kids</th>\n",
       "      <th>is_christmas</th>\n",
       "      <th>is_nursery</th>\n",
       "      <th>is_religious</th>\n",
       "      <th>language_raw</th>\n",
       "      <th>main_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6KbQ3uYMLKb5jDxLF7wYDD</td>\n",
       "      <td>Singende Bataillone 1. Teil</td>\n",
       "      <td>['Carl Woitschach']</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>...</td>\n",
       "      <td>158648</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>Warm Emotional Acoustic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6KuQTIu1KoTTkLXKrwlLPV</td>\n",
       "      <td>Fantasiestücke, Op. 111: Più tosto lento</td>\n",
       "      <td>['Robert Schumann', 'Vladimir Horowitz']</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>...</td>\n",
       "      <td>282133</td>\n",
       "      <td>1</td>\n",
       "      <td>1_0</td>\n",
       "      <td>Deep Minimal Calm</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6L63VW0PibdM1HDSBoqnoM</td>\n",
       "      <td>Chapter 1.18 - Zamek kaniowski</td>\n",
       "      <td>['Seweryn Goszczyński']</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>...</td>\n",
       "      <td>104300</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>Spoken Chill &amp; Emotional</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>pl</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6M94FkXd15sOAOQYRnWPN8</td>\n",
       "      <td>Bebamos Juntos - Instrumental (Remasterizado)</td>\n",
       "      <td>['Francisco Canaro']</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>...</td>\n",
       "      <td>180760</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>Warm Emotional Acoustic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>pt</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6N6tiFZ9vLTSOIxkj8qKrd</td>\n",
       "      <td>Polonaise-Fantaisie in A-Flat Major, Op. 61</td>\n",
       "      <td>['Frédéric Chopin', 'Vladimir Horowitz']</td>\n",
       "      <td>1</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>...</td>\n",
       "      <td>687733</td>\n",
       "      <td>1</td>\n",
       "      <td>1_0</td>\n",
       "      <td>Deep Minimal Calm</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                                     track_name  \\\n",
       "0  6KbQ3uYMLKb5jDxLF7wYDD                    Singende Bataillone 1. Teil   \n",
       "1  6KuQTIu1KoTTkLXKrwlLPV       Fantasiestücke, Op. 111: Più tosto lento   \n",
       "2  6L63VW0PibdM1HDSBoqnoM                 Chapter 1.18 - Zamek kaniowski   \n",
       "3  6M94FkXd15sOAOQYRnWPN8  Bebamos Juntos - Instrumental (Remasterizado)   \n",
       "4  6N6tiFZ9vLTSOIxkj8qKrd    Polonaise-Fantaisie in A-Flat Major, Op. 61   \n",
       "\n",
       "                                artist_name  popularity  year  acousticness  \\\n",
       "0                       ['Carl Woitschach']           0  1928         0.995   \n",
       "1  ['Robert Schumann', 'Vladimir Horowitz']           0  1928         0.994   \n",
       "2                   ['Seweryn Goszczyński']           0  1928         0.604   \n",
       "3                      ['Francisco Canaro']           0  1928         0.995   \n",
       "4  ['Frédéric Chopin', 'Vladimir Horowitz']           1  1928         0.990   \n",
       "\n",
       "   danceability  energy  instrumentalness  liveness  ...  duration_ms  \\\n",
       "0         0.708  0.1950             0.563    0.1510  ...       158648   \n",
       "1         0.379  0.0135             0.901    0.0763  ...       282133   \n",
       "2         0.749  0.2200             0.000    0.1190  ...       104300   \n",
       "3         0.781  0.1300             0.887    0.1110  ...       180760   \n",
       "4         0.210  0.2040             0.908    0.0980  ...       687733   \n",
       "\n",
       "   macro_cluster  subcluster          subcluster_label  is_kids  is_christmas  \\\n",
       "0              1         1_1   Warm Emotional Acoustic    False         False   \n",
       "1              1         1_0         Deep Minimal Calm    False         False   \n",
       "2              0         0_0  Spoken Chill & Emotional    False         False   \n",
       "3              1         1_1   Warm Emotional Acoustic    False         False   \n",
       "4              1         1_0         Deep Minimal Calm    False         False   \n",
       "\n",
       "  is_nursery is_religious  language_raw  main_language  \n",
       "0      False        False            de             de  \n",
       "1      False        False            de             de  \n",
       "2      False        False            pl          other  \n",
       "3      False        False            pt             pt  \n",
       "4      False        False            fr             fr  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PROCESSED_DIR = os.path.join(\"..\", \"data\", \"processed\")\n",
    "data_path = os.path.join(DATA_PROCESSED_DIR, \"spotify_dataset_clustered.csv\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a87982af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe con subcluster: (169909, 24)\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"subcluster\"].notna()].copy()\n",
    "print(\"Righe con subcluster:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7a0190",
   "metadata": {},
   "source": [
    "# Cell 2 - Selecting Audio features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e9ffb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di subcluster (classi): 10\n",
      "Classi: ['0_0' '1_0' '1_1' '1_2' '2_0' '2_1' '2_2' '2_3' '2_4' '2_5']\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    \"acousticness\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"loudness\",\n",
    "    \"speechiness\",\n",
    "    \"tempo\",\n",
    "    \"valence\",\n",
    "    \"duration_ms\",\n",
    "]\n",
    "\n",
    "X = df[feature_cols].values\n",
    "\n",
    "# Target: subcluster (es. \"2_5\")\n",
    "y_str = df[\"subcluster\"].astype(str).values\n",
    "\n",
    "# Encodiamo i subcluster in interi 0..K-1\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_str)\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Numero di subcluster (classi):\", num_classes)\n",
    "print(\"Classi:\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33147cd1",
   "metadata": {},
   "source": [
    "# Cell 3 - Train/val/test split + scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dea558c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (135927, 10) Val: (16991, 10) Test: (16991, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7b25ad",
   "metadata": {},
   "source": [
    "# Cell 4 - Dataset & DataLoader PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14bf908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpotifyClusterDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)   # long per CrossEntropy\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = SpotifyClusterDataset(X_train_scaled, y_train)\n",
    "val_ds   = SpotifyClusterDataset(X_val_scaled, y_val)\n",
    "test_ds  = SpotifyClusterDataset(X_test_scaled, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=256, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8b9c4",
   "metadata": {},
   "source": [
    "# Cell 5 - Definition of the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0a521117",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(feature_cols)\n",
    "hidden_dim = 64   # o 128, come avevi prima\n",
    "\n",
    "class MLPCluster(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, num_classes)  # <-- K classi\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = MLPCluster(input_dim, hidden_dim, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a99a545",
   "metadata": {},
   "source": [
    "# Cell 6 - train/val per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f426dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | train loss: 0.5838, acc: 0.809 | val loss: 0.2167, acc: 0.921\n",
      "Epoch 2/20 | train loss: 0.2830, acc: 0.892 | val loss: 0.1841, acc: 0.930\n",
      "Epoch 3/20 | train loss: 0.2514, acc: 0.903 | val loss: 0.1706, acc: 0.932\n",
      "Epoch 4/20 | train loss: 0.2308, acc: 0.910 | val loss: 0.1604, acc: 0.937\n",
      "Epoch 5/20 | train loss: 0.2178, acc: 0.915 | val loss: 0.1552, acc: 0.939\n",
      "Epoch 6/20 | train loss: 0.2081, acc: 0.919 | val loss: 0.1505, acc: 0.940\n",
      "Epoch 7/20 | train loss: 0.1979, acc: 0.923 | val loss: 0.1438, acc: 0.943\n",
      "Epoch 8/20 | train loss: 0.1938, acc: 0.925 | val loss: 0.1410, acc: 0.943\n",
      "Epoch 9/20 | train loss: 0.1884, acc: 0.927 | val loss: 0.1370, acc: 0.944\n",
      "Epoch 10/20 | train loss: 0.1840, acc: 0.928 | val loss: 0.1330, acc: 0.947\n",
      "Epoch 11/20 | train loss: 0.1809, acc: 0.931 | val loss: 0.1327, acc: 0.948\n",
      "Epoch 12/20 | train loss: 0.1782, acc: 0.932 | val loss: 0.1308, acc: 0.949\n",
      "Epoch 13/20 | train loss: 0.1749, acc: 0.932 | val loss: 0.1283, acc: 0.949\n",
      "Epoch 14/20 | train loss: 0.1731, acc: 0.932 | val loss: 0.1288, acc: 0.949\n",
      "Epoch 15/20 | train loss: 0.1707, acc: 0.933 | val loss: 0.1258, acc: 0.949\n",
      "Epoch 16/20 | train loss: 0.1694, acc: 0.934 | val loss: 0.1254, acc: 0.951\n",
      "Epoch 17/20 | train loss: 0.1669, acc: 0.935 | val loss: 0.1249, acc: 0.950\n",
      "Epoch 18/20 | train loss: 0.1661, acc: 0.935 | val loss: 0.1251, acc: 0.949\n",
      "Epoch 19/20 | train loss: 0.1648, acc: 0.936 | val loss: 0.1229, acc: 0.951\n",
      "Epoch 20/20 | train loss: 0.1633, acc: 0.936 | val loss: 0.1222, acc: 0.951\n",
      "Loaded best model: val_loss=0.1222, val_acc=0.951\n"
     ]
    }
   ],
   "source": [
    "def run_epoch(loader, model, criterion, optimizer=None):\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y_batch.size(0)\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_val_acc = 0.0\n",
    "best_state_dict = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = run_epoch(train_loader, model, criterion, optimizer)\n",
    "    val_loss, val_acc = run_epoch(val_loader, model, criterion, optimizer=None)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{EPOCHS} | \"\n",
    "        f\"train loss: {train_loss:.4f}, acc: {train_acc:.3f} | \"\n",
    "        f\"val loss: {val_loss:.4f}, acc: {val_acc:.3f}\"\n",
    "    )\n",
    "\n",
    "    # ✅ aggiorna il best model (qui uso val_loss come criterio principale;\n",
    "    # in caso di pareggio, scelgo quello con val_acc migliore)\n",
    "    if (val_loss < best_val_loss) or (\n",
    "        np.isclose(val_loss, best_val_loss) and val_acc > best_val_acc\n",
    "    ):\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        best_state_dict = model.state_dict()\n",
    "\n",
    "# ✅ alla fine del training, ricarichiamo i pesi migliori trovati\n",
    "if best_state_dict is not None:\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    print(\n",
    "        f\"Loaded best model: val_loss={best_val_loss:.4f}, \"\n",
    "        f\"val_acc={best_val_acc:.3f}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Warning: nessun best_state_dict salvato (controlla il loop di training).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1a5a2",
   "metadata": {},
   "source": [
    "# Cell 7 - Validation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67363c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9489729856983109\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.99      0.98      0.98       387\n",
      "         1_0       0.95      0.97      0.96      1337\n",
      "         1_1       0.95      0.94      0.95      1278\n",
      "         1_2       0.93      0.96      0.94       717\n",
      "         2_0       0.93      0.95      0.94      2190\n",
      "         2_1       0.95      0.95      0.95      2714\n",
      "         2_2       0.96      0.96      0.96      3470\n",
      "         2_3       0.97      0.94      0.95      1962\n",
      "         2_4       0.92      0.92      0.92      1974\n",
      "         2_5       0.94      0.96      0.95       962\n",
      "\n",
      "    accuracy                           0.95     16991\n",
      "   macro avg       0.95      0.95      0.95     16991\n",
      "weighted avg       0.95      0.95      0.95     16991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(X_batch)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_true.append(y_batch.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_true = np.concatenate(all_true)\n",
    "\n",
    "print(\"Test accuracy:\", (all_preds == all_true).mean())\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(all_true, all_preds, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e398e",
   "metadata": {},
   "source": [
    "# Cell 8 - Saving Model & Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f0e8517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(\"..\", \"models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(MODEL_DIR, \"mlp_subcluster.pth\"))\n",
    "np.save(os.path.join(MODEL_DIR, \"scaler_mean.npy\"), scaler.mean_)\n",
    "np.save(os.path.join(MODEL_DIR, \"scaler_scale.npy\"), scaler.scale_)\n",
    "np.save(os.path.join(MODEL_DIR, \"label_encoder_classes.npy\"), le.classes_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
